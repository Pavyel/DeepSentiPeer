{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import predict\n",
    "from sentence_encoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_padded, label_scale, aspects = predict.prepare_data('../../data/iclr_2017')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (papers, paper obj, review, no.reviews, reviews, decision), aspects_score = data_padded_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_dev, y_dev,x_test, y_test = data_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_paper = x_train[0]\n",
    "x_review = x_train[4]\n",
    "# x_num_reviews = x_train[3]\n",
    "x_decision = x_train[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_paper = x_dev[0]\n",
    "d_review = x_dev[4]\n",
    "# d_num_reviews = x_dev[3]\n",
    "d_decision = x_dev[5]\n",
    "\n",
    "t_paper = x_test[0]\n",
    "t_review = x_test[4]\n",
    "# t_num_reviews = x_test[3]\n",
    "t_decision = x_test[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp_acl = xtacl[0]\n",
    "# tr_acl = xtacl[4]\n",
    "# td_acl = xtacl[5]\n",
    "\n",
    "# dp_acl = xdacl[0]\n",
    "# dr_acl = xdacl[4]\n",
    "# dd_acl = xdacl[5]\n",
    "\n",
    "# cp_acl = tacl[0]\n",
    "# cr_acl = tacl[4]\n",
    "# cd_acl = tacl[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data):\n",
    "    papers, reviews, decision = data \n",
    "    reviews_embedded = embed(reviews)\n",
    "    papers_embedded = embed(papers)\n",
    "    sentiment_scores = sentiment(reviews)\n",
    "    #papers_embedded = np.repeat(papers_embedded, num_reviews, axis = 0)\n",
    "    decision = np.array(decision).astype(int)\n",
    "    #decision = np.repeat(decision, num_reviews, axis = 0)\n",
    "    return papers_embedded, reviews_embedded, sentiment_scores, decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_train, reviews_train, sentiment_train, decision_train = get_data((x_paper, x_review, x_decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (papers_train, reviews_train, sentiment_train, decision_train):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_valid, reviews_valid, sentiment_valid, decision_valid = get_data((d_paper, d_review, d_decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (papers_valid, reviews_valid, sentiment_valid, decision_valid):\n",
    "    print i.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_train = np.pad(papers_train, [(0,0),(0, 1494-666), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_valid = papers_valid[:,:1494,:]\n",
    "reviews_valid = np.pad(reviews_valid, [(0,0),(0, 525-318), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "sentiment_valid = np.pad(sentiment_valid, [(0,0),(0, 525-318), (0,0)], mode = 'constant', constant_values = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (papers_valid, reviews_valid, sentiment_valid, decision_valid):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_test, reviews_test, sentiment_test, decision_test = get_data((t_paper, t_review, t_decision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (papers_test, reviews_test, sentiment_test, decision_test):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_test = np.pad(papers_test, [(0,0),(0, 1494-419), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "reviews_test = np.pad(reviews_test, [(0,0),(0, 525-309), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "sentiment_test = np.pad(sentiment_test, [(0,0),(0, 525-309), (0,0)], mode = 'constant', constant_values = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iclr-2018 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ICLR-2018\n",
    "#### 573 Rejected 336 Accepted Papers, 909 Papers, 2741 Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import predict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_padded_, label_scale_, aspects_ = predict1.prepare_data('../../data/iclr_2018')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (papers, paper obj, review, no.reviews, reviews, decision), aspects_score = data_padded_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = []\n",
    "for paper in data_padded_[0][1]:\n",
    "    decision.append(paper.__dict__['ACCEPTED'])\n",
    "decision = np.array(decision).astype(int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_, ytrain_ = data_padded_\n",
    "papers_, _,_,_,reviews_,decision_ = train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_vec, review_vec, sentic_vec, dcsn_vec = get_data((papers_[:500], reviews_[:500], decision_[:500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (paper_vec, review_vec, sentic_vec, dcsn_vec):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_vec1, review_vec1, sentic_vec1, dcsn_vec1 = get_data((papers_[500:], reviews_[500:], decision_[500:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (paper_vec1, review_vec1, sentic_vec1, dcsn_vec1):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_paper_sent = max(paper_vec1.shape[1], paper_vec.shape[1])\n",
    "max_review_sent = max(review_vec1.shape[1], review_vec.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_vec = np.pad(paper_vec, [(0,0),(0, max_paper_sent-paper_vec.shape[1]), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "review_vec1 = np.pad(review_vec1, [(0,0),(0, max_review_sent-review_vec1.shape[1]), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "sentic_vec1 = np.pad(sentic_vec1, [(0,0),(0, max_review_sent-sentic_vec1.shape[1]), (0,0)], mode = 'constant', constant_values = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_v = np.concatenate((paper_vec, paper_vec1), axis=0)\n",
    "review_v = np.concatenate((review_vec, review_vec1), axis=0)\n",
    "sentic_v = np.concatenate((sentic_vec, sentic_vec1), axis=0)\n",
    "dcsn_v = np.concatenate((dcsn_vec, dcsn_vec1), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentic_v = np.pad(sentic_v, [(0,0),(0, 525-sentic_v.shape[1]), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "review_v = np.pad(review_v, [(0,0),(0, 525-review_v.shape[1]), (0,0)], mode = 'constant', constant_values = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (paper_v, review_v, sentic_v, dcsn_v):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Concatenate 2017 and 2018 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# papers_train = np.load('./serial/iclr2017/train/papers.npy')\n",
    "# reviews_train = np.load('./serial/iclr2017/train/reviews.npy')\n",
    "# sentiment_train = np.load('./serial/iclr2017/train/sentic.npy')\n",
    "# decision_train = np.load('./serial/iclr2017/train/dcsn.npy')\n",
    "\n",
    "# papers_valid = np.load('./serial/iclr2017/dev/papers.npy')\n",
    "# reviews_valid = np.load('./serial/iclr2017/dev/reviews.npy')\n",
    "# sentiment_valid = np.load('./serial/iclr2017/dev/sentic.npy')\n",
    "# decision_valid = np.load('./serial/iclr2017/dev/dcsn.npy')\n",
    "\n",
    "\n",
    "papers_test = np.load('./serial/iclr2017/test/papers.npy')\n",
    "reviews_test = np.load('./serial/iclr2017/test/reviews.npy')\n",
    "sentiment_test = np.load('./serial/iclr2017/test/sentic.npy')\n",
    "decision_test = np.load('./serial/iclr2017/test/dcsn.npy')\n",
    "\n",
    "\n",
    "# paper_v = np.load('./serial/iclr2018/papers.npy')\n",
    "# review_v = np.load('./serial/iclr2018/reviews.npy')\n",
    "# sentic_v = np.load('./serial/iclr2018/sentic.npy')\n",
    "# dcsn_v = np.load('./serial/iclr2018/dcsn.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 1494, 512)\n",
      "(38, 525, 512)\n",
      "(38, 525, 4)\n",
      "(38,)\n"
     ]
    }
   ],
   "source": [
    "for i in (papers_test,reviews_test,sentiment_test,decision_test):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "for i in zip((papers_train, reviews_train, sentiment_train, decision_train), (paper_v, review_v, sentic_v, dcsn_v)):\n",
    "    train_data.append(np.concatenate((i[0], i[1]), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 1494, 512)\n",
      "(1258, 525, 512)\n",
      "(1258, 525, 4)\n",
      "(1258,)\n"
     ]
    }
   ],
   "source": [
    "for i in train_data:\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_p, train_r, train_s, train_d = shuffle(train_data[0], train_data[1], train_data[2], train_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1258, 1494, 512)\n",
      "(1258, 525, 512)\n",
      "(1258, 525, 4)\n",
      "(1258,)\n"
     ]
    }
   ],
   "source": [
    "for i in (train_p, train_r, train_s, train_d):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACL_2017 Cross-Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import predict1\n",
    "data_padded_, label_scale_, aspects_ = predict1.prepare_data('../../data/iclr_2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_padded_[0]:\n",
    "    print len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data_padded_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paper in data_padded_[0][1]:\n",
    "    print paper.__dict__['ACCEPTED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "none = np.where(np.array(x[5]) == None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcsn = np.array(x[5])\n",
    "dcsn[none] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcsn = dcsn.tolist()\n",
    "# dcsn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt,rt,st,dt = get_data((x[0],x[4],dcsn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in (pt,rt,st,dt):\n",
    "    print i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = np.pad(pt, [(0,0),(0, 1494-1373), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "rt = np.pad(rt, [(0,0),(0, 525-156), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "st = np.pad(st, [(0,0),(0, 525-156), (0,0)], mode = 'constant', constant_values = 0.0)\n",
    "tt = (pt,rt,st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "torch.cuda.set_device(7)\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classify(nn.Module):\n",
    "    def __init__(self, rh1, ch1):\n",
    "        super(classify, self).__init__()\n",
    "        \n",
    "        num_classes = 2\n",
    "        \n",
    "#         self.p3 = nn.Sequential(\n",
    "#                             nn.Conv1d(in_channels = 512, out_channels = 256, kernel_size = 5),\n",
    "#                             nn.ReLU()\n",
    "#                             )\n",
    "        self.r3 = nn.Sequential(\n",
    "                            nn.Conv1d(in_channels = 512, out_channels = 64, kernel_size = 5),\n",
    "                            nn.ReLU()\n",
    "                            )\n",
    "    \n",
    "        self.s1 = nn.Linear(4*525,rh1)\n",
    "\n",
    "        self.l1 = nn.Linear(64, ch1)\n",
    "        \n",
    "        self.l3 = nn.Linear(2*100,100)\n",
    "        self.l4 = nn.Linear(100, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p = 0.7)\n",
    "        \n",
    "    def forward(self, paper, review, sentiment):  \n",
    "        batch_size = paper.shape[0]\n",
    "#         out_p3 = self.p3(paper)\n",
    "#         out_p3 = F.max_pool1d(out_p3, out_p3.shape[2])\n",
    "\n",
    "        out_r3 = self.r3(review)\n",
    "        out_r3 = F.max_pool1d(out_r3, out_r3.shape[2])    #out_p/r shape = (batch_size, #filters, 1)\n",
    "        \n",
    "#         out = torch.cat((out_p3, out_r3), dim = 1)         #out shape = (batch_size, num_filters*kernels, 1)\n",
    "        out = out_r3\n",
    "        \n",
    "        r = self.s1(sentiment.view(batch_size, -1))\n",
    "        r = self.dropout(r)\n",
    "        \n",
    "        out = self.l1(out.view(batch_size, -1))\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        out = self.l3(torch.cat((out, r), dim = 1))\n",
    "        out = self.dropout(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l4(out)\n",
    "    \n",
    "        \n",
    "        return out,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = classify(100,100).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters()) #,weight_decay = 0.0, momentum = 0.9, lr = 0.009)\n",
    "#loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dset(Dataset):\n",
    "    def __init__(self, data, y_data):\n",
    "        x1, x2, x3 = data\n",
    "        assert x1.shape[0] == x2.shape[0]\n",
    "        assert x1.shape[0] == x3.shape[0]\n",
    "        self.len = x1.shape[0]\n",
    "        self.x1_data = x1\n",
    "        self.x2_data = x2\n",
    "        self.x3_data = x3\n",
    "        self.y_data = y_data\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x1_data[index,:,:], self.x2_data[index,:,:], self.x3_data[index,:,:]), self.y_data[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(Dset, batch_size, num_workers):\n",
    "    loader = DataLoader(Dset, batch_size = batch_size, shuffle = False, num_workers = num_workers)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy(preds, true):\n",
    "#     preds = preds.detach().cpu().numpy()\n",
    "#     true = true.detach().cpu().numpy()\n",
    "#     labels = np.argmax(preds, axis = 1)\n",
    "#     return np.sum(np.array(labels == true).astype(int))/float(true.shape[0]), zip(labels, true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainD = dset((train_p, train_r, train_s), train_d)\n",
    "trainloader = load_data(trainD, batch_size = 32, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "validD = dset((papers_valid, reviews_valid, sentiment_valid), decision_valid)\n",
    "validloader = load_data(validD, batch_size = 32, num_workers = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, params):\n",
    "    model.train()\n",
    "    steps = 0\n",
    "    loss_log = []\n",
    "    acc_log = []\n",
    "    best_val_acc = 0.0\n",
    "    log_after_interval = params['log_after_interval']\n",
    "    eval_after_interval = params['eval_after_interval']\n",
    "    epochs = params['epochs']\n",
    "    writer = SummaryWriter(comment = 'Decision(r+s),' + str(params['lr']) + ' ' + str(params['l2']))\n",
    "    for epoch in range(epochs):\n",
    "        training_loss = []\n",
    "        training_acc = []\n",
    "        for i, data in enumerate(trainloader,0):\n",
    "            (papers, reviews, sentiment), decision = data\n",
    "            papers = papers.transpose(1,2).float().to(device)\n",
    "            reviews = reviews.transpose(1,2).float().to(device)\n",
    "            sentiment = sentiment.transpose(1,2).float().to(device)\n",
    "            decision = decision.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(papers, reviews, sentiment)\n",
    "            \n",
    "            pred = (torch.max(out, 1)[1].view(decision.size()).data == decision.data).sum()\n",
    "            acc = (pred.item()/decision.size()[0])\n",
    "            \n",
    "            los = F.cross_entropy(out, decision)\n",
    "            training_loss.append(los.item())\n",
    "            training_acc.append(acc)\n",
    "            loss_log.append(los.item())\n",
    "            acc_log.append(acc)\n",
    "            \n",
    "            los.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if steps%log_after_interval == 0:\n",
    "#                 pred = (torch.max(out, 1)[1].view(decision.size()).data == decision.data).sum()\n",
    "#                 acc = (pred.item()/decision.size()[0])\n",
    "                print('Epoch[{}/{}] Iteration[{}]-loss: {:.6f} acc: {:.4f}'.format(epoch, epochs, steps, np.average(loss_log), np.average(acc_log)))\n",
    "                loss_log = []\n",
    "                acc_log = []\n",
    "            if steps%eval_after_interval == 0:\n",
    "                dl, da = evaluate(validloader, model)\n",
    "                if best_val_acc < da:\n",
    "                    best_val_acc = da\n",
    "                    print('Saving model with validation accuracy: {}'.format(da))\n",
    "                    checkpoint = {'model_state_dict': model.state_dict(),\n",
    "                                'optimizer_state_dict':optimizer.state_dict(),\n",
    "                                }\n",
    "                    with open('./trained_task2/rs/' + params['iteration'] + '.model', 'wb') as f:\n",
    "                        torch.save(checkpoint, f)\n",
    "                    with open('./trained_task2/rs/' + params['iteration'] + '.json', 'w') as f:\n",
    "                        json.dump(params, f)\n",
    "            steps+=1\n",
    "        writer.add_scalar('training_loss', np.average(training_loss), epoch)\n",
    "        writer.add_scalar('training_acc', np.average(training_acc), epoch)\n",
    "            \n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(validloader, model):\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    model.eval()\n",
    "    for i, data in enumerate(validloader,0):\n",
    "        (papers, reviews, sentiment), decision = data\n",
    "        papers = papers.transpose(1,2).float().to(device)\n",
    "        reviews = reviews.transpose(1,2).float().to(device)\n",
    "        sentiment = sentiment.transpose(1,2).float().to(device)\n",
    "        decision = decision.to(device)\n",
    "        \n",
    "        out,r = model(papers, reviews, sentiment)\n",
    "        los = F.cross_entropy(out, decision)\n",
    "        val_loss.append(los.item())\n",
    "        pred = (torch.max(out, 1)[1].view(decision.size()).data == decision.data).sum()\n",
    "        acc = (pred.item()/decision.size()[0])\n",
    "        val_acc.append(acc)\n",
    "    print('Evaluation- loss: {:.6f} acc: {:.4f}'.format(np.average(val_loss), np.average(val_acc)))#, pred,decision.size()[0]))\n",
    "    return np.average(val_loss), np.average(val_acc), out,decision,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Gridtest():\n",
    "\n",
    "    lrate = [0.5,0.1, 0.07, 0.05, 0.03, 0.01, 0.007, 0.005, 0.003,0.001, 0.0007, 0.0005, 0.0003, 0.0001, 0.00005]\n",
    "    decay = [0.0001, 0.005, 0.001, 0.05, 0.01, 0.5, 0.1, 0.0, 1.0, 2.0 ]\n",
    "\n",
    "    for l in lrate:\n",
    "        for d in decay:\n",
    "            print('testing with lr {} and l2 {}'.format(l, d))\n",
    "            params = {\n",
    "                         'optimizer': 'SGD',\n",
    "                         'Type': 'Review+Sentiment',\n",
    "                         'Filter_size': '64 on review',\n",
    "                         'Dropout': 0.7,\n",
    "                        'lr':l,\n",
    "                        'l2': d,\n",
    "                        'batch-size': 32,\n",
    "                         'iteration': str(int(time.time())),\n",
    "                        'epochs': 50,\n",
    "                        'log_after_interval': 20,\n",
    "                        'eval_after_interval': 20\n",
    "            }\n",
    "            model = classify(100,100).to(device)\n",
    "            optimizer = torch.optim.SGD(model.parameters(),weight_decay = d, momentum = 0.9, lr = l)\n",
    "            train(model, optimizer, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gridtest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in glob.glob('./trained_task2/rs/?*.model'):\n",
    "    checkpoint = torch.load(f)\n",
    "    testD = dset(tt, dt)\n",
    "    testloader = load_data(testD, batch_size = 32, num_workers = 1)\n",
    "    model = classify(100,100).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    #model.load_state_dict(torch.load('prediction.model'))\n",
    "    _, _ ,p,d,r = evaluate(testloader, model)\n",
    "###Evaluation- loss: 0.825200 acc: 0.7105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = (torch.max(p, 1)   )[1] #.view(decision.size()).data == decision.data)\n",
    "# acc = (pred.item()/decision.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# act = r.cpu().detach().numpy()\n",
    "# act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# act_embedded = TSNE(n_components=2).fit_transform(act)\n",
    "# act_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# cm = plt.cm.get_cmap('RdYlBu')\n",
    "# # co = pred.cpu().detach().numpy()\n",
    "# # plt.scatter(act_embedded[:,0], act_embedded[:,1], c=co, marker = markers)\n",
    "# # ax.set_xlim([-200,200])\n",
    "# # ax.set_ylim([-200,200])\n",
    "# # plt.show()\n",
    "# correct = np.where(pred.cpu().detach().numpy() == d.cpu().detach().numpy())\n",
    "# wrong = np.where(pred.cpu().detach().numpy() != d.cpu().detach().numpy())\n",
    "# act_correct = act_embedded[correct]\n",
    "# act_wrong = act_embedded[wrong]\n",
    "# f, ax = plt.subplots(figsize = (3.5,2.5))\n",
    "# plt.scatter(act_correct[:,0], act_correct[:,1], marker='o', c=pred.cpu().detach().numpy()[correct])\n",
    "# plt.scatter(act_wrong[:,0], act_wrong[:,1], marker='x', c=pred.cpu().detach().numpy()[wrong])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# co = pred.cpu().detach().numpy()[correct]\n",
    "# co"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('iclr2017_test.txt', 'w') as f:\n",
    "#     for i in range(len(x_test[1])):\n",
    "#         f.write(x_test[1][i].__dict__['TITLE']+'\\t'+(str(pred[i].item())+','+str(d[i].item())))\n",
    "#         f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = {'model_state_dict': model.state_dict(),\n",
    "#                 'optimizer_state_dict':optimizer.state_dict(),\n",
    "#                 'batch_size': 32}\n",
    "# params = {\n",
    "#              'optimizer': 'Adam',\n",
    "#              'Type': 'Review+Sentiment',\n",
    "#              'Filter_size': '64 on review',\n",
    "#              'Dropout': 0.7,\n",
    "#              'iteration': str(int(time.time()))\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./trained_task2/rs/' + params['iteration'] + '.model', 'wb') as f:\n",
    "#                         torch.save(checkpoint, f)\n",
    "# with open('./trained_task2/rs/' + params['iteration'] + '.json', 'w') as f:\n",
    "#         json.dump(params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jcdl",
   "language": "python",
   "name": "jcdl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
